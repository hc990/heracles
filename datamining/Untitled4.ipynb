{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3aa1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "MPS backend enabled for M4 GPU acceleration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/89kgtpnn77vc6rkbbypgww8m0000gn/T/ipykernel_10952/2828260833.py:197: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Loss: 0.790992, Train Acc: 0.692533, Test Acc: 0.694100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 224, 224) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 224\u001b[0m\n\u001b[1;32m    222\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    223\u001b[0m train(net, train_iter, test_iter, loss_fn, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 224\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [3], line 216\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(net, test_iter, device, n)\u001b[0m\n\u001b[1;32m    214\u001b[0m preds \u001b[38;5;241m=\u001b[39m get_fashion_mnist_labels(net(X)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    215\u001b[0m titles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m true, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trues, preds)]\n\u001b[0;32m--> 216\u001b[0m \u001b[43mshow_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitles\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [3], line 77\u001b[0m, in \u001b[0;36mshow_images\u001b[0;34m(imgs, num_rows, num_cols, titles, scale)\u001b[0m\n\u001b[1;32m     75\u001b[0m axes \u001b[38;5;241m=\u001b[39m axes\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (ax, img) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(axes, imgs)):\n\u001b[0;32m---> 77\u001b[0m     \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     ax\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mget_xaxis()\u001b[38;5;241m.\u001b[39mset_visible(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m     ax\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mget_yaxis()\u001b[38;5;241m.\u001b[39mset_visible(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.virtualenvs/heracles/lib/python3.9/site-packages/matplotlib/__init__.py:1476\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1476\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1481\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1482\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1483\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.virtualenvs/heracles/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5895\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5896\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/heracles/lib/python3.9/site-packages/matplotlib/image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    728\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/heracles/lib/python3.9/site-packages/matplotlib/image.py:697\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    695\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 224, 224) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 1. 检查 MPS 可用性并设置设备\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'mps':\n",
    "    print(\"MPS backend enabled for M4 GPU acceleration\")\n",
    "else:\n",
    "    print(\"Warning: MPS not available, falling back to CPU\")\n",
    "\n",
    "# 2. 数据加载：Fashion-MNIST\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    transform_list = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        transform_list.insert(0, transforms.Resize(resize))\n",
    "    transform = transforms.Compose(transform_list)\n",
    "    train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# 3. 辅助函数\n",
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "    \n",
    "    def add(self, *args):\n",
    "        for i, arg in enumerate(args):\n",
    "            if isinstance(arg, (int, float)):\n",
    "                self.data[i] += arg\n",
    "            else:\n",
    "                raise ValueError(f\"Expected numeric value, got {type(arg)}\")\n",
    "    \n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    _, preds = torch.max(y_hat, 1)\n",
    "    return (preds == y).sum().item()\n",
    "\n",
    "def evaluate_accuracy(net, data_iter, device):\n",
    "    net.eval()\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "\n",
    "\n",
    "    \n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save\n",
    "    \"\"\"绘制图像列表\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        ax.imshow(img.cpu().numpy())\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes\n",
    "\n",
    "class Animator:\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.'), nrows=1, ncols=1,\n",
    "                 figsize=(10, 6)):\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes]\n",
    "        self.xlabel, self.ylabel = xlabel, ylabel\n",
    "        self.xlim, self.ylim = xlim, ylim\n",
    "        self.xscale, self.yscale = xscale, yscale\n",
    "        self.legend = legend\n",
    "        self.fmts = fmts\n",
    "        self.X, self.Y = None, None\n",
    "    \n",
    "    def add(self, x, y):\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.axes[0].set_xlabel(self.xlabel)\n",
    "        self.axes[0].set_ylabel(self.ylabel)\n",
    "        self.axes[0].set_xlim(self.xlim)\n",
    "        self.axes[0].set_ylim(self.ylim)\n",
    "        self.axes[0].set_xscale(self.xscale)\n",
    "        self.axes[0].set_yscale(self.yscale)\n",
    "        if self.legend:\n",
    "            self.axes[0].legend(self.legend)\n",
    "        self.axes[0].grid()\n",
    "        plt.savefig(\"training_progress.png\")\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        \n",
    "# 4. AlexNet 模型（添加 torch.cat 示例）\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 5 * 5, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        # 初始化权重（类似 RNN 的 torch.normal）\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, aux_input=None):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        if aux_input is not None:  # Example: Concatenate auxiliary input (e.g., sensor data)\n",
    "            aux_input = aux_input.to(x.device)\n",
    "            x = torch.cat((x, aux_input), dim=1)  # Requires matching dimensions\n",
    "            x = nn.Linear(x.shape[1], self.classifier[-1].out_features)(x)\n",
    "        return x\n",
    "\n",
    "# 5. 训练函数\n",
    "def train_epoch(net, train_iter, loss_fn, optimizer, device, scaler):\n",
    "    metric = Accumulator(3)\n",
    "    net.train()\n",
    "    for X, y in train_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            y_hat = net(X.to(device))\n",
    "            loss = loss_fn(y_hat, y.to(device))\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        except RuntimeError as e:\n",
    "            print(f\"MPS error: {e}. Falling back to CPU for this batch.\")\n",
    "            X, y = X.to('cpu'), y.to('cpu')\n",
    "            net.to('cpu')\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            net.to(device)\n",
    "        with torch.no_grad():\n",
    "            metric.add(loss.item() * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def train(net, train_iter, test_iter, loss_fn, num_epochs, lr, device):\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "    scaler = GradScaler()\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.0, 1.0],\n",
    "                       legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(net, train_iter, loss_fn, optimizer, device, scaler)\n",
    "        test_acc = evaluate_accuracy(net, test_iter, device)\n",
    "        animator.add(epoch + 1, (train_loss, train_acc, test_acc))\n",
    "    print(f\"Final Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.6f}, Test Acc: {test_acc:.6f}\")\n",
    "\n",
    "# 6. 预测函数\n",
    "def predict(net, test_iter, device, n=10):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            break\n",
    "        trues = get_fashion_mnist_labels(y)\n",
    "        preds = get_fashion_mnist_labels(net(X).argmax(dim=1))\n",
    "        titles = [f\"{true}\\n{pred}\" for true, pred in zip(trues, preds)]\n",
    "        show_images(X.cpu()[:n], 1, n, titles=titles[:n])\n",
    "    \n",
    "# 7. 运行训练和预测\n",
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "net = AlexNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train(net, train_iter, test_iter, loss_fn, num_epochs=10, lr=0.01, device=device)\n",
    "predict(net, test_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1d72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
