{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472c3464",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FixedHiddenMLP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(X))\n\u001b[1;32m     87\u001b[0m chimera \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m---> 88\u001b[0m chimera\u001b[38;5;241m.\u001b[39madd(NestMLP(), nn\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m20\u001b[39m), \u001b[43mFixedHiddenMLP\u001b[49m())\n\u001b[1;32m     89\u001b[0m chimera\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[1;32m     90\u001b[0m chimera(X)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FixedHiddenMLP' is not defined"
     ]
    }
   ],
   "source": [
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "# net = nn.Sequential()\n",
    "# net.add(nn.Dense(256, activation='relu'))\n",
    "# net.add(nn.Dense(10))\n",
    "# net.initialize()\n",
    "\n",
    "X = np.random.uniform(size=(2, 20))\n",
    "# net(X)\n",
    "\n",
    "# class MLP(nn.Block):\n",
    "#     # 用模型参数声明层。这里，我们声明两个全连接的层\n",
    "#     def __init__(self, **kwargs):\n",
    "#         # 调用MLP的父类Block的构造函数来执行必要的初始化。\n",
    "#         # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.hidden = nn.Dense(256, activation='relu')  # 隐藏层\n",
    "#         self.out = nn.Dense(10)  # 输出层\n",
    "\n",
    "#     # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n",
    "#     def forward(self, X):\n",
    "#         return self.out(self.hidden(X))\n",
    "    \n",
    "    \n",
    "# net = MLP()\n",
    "# net.initialize()\n",
    "# net(X)\n",
    "# class MySequential(nn.Block):\n",
    "#     def add(self, block):\n",
    "#     # 这里，block是Block子类的一个实例，我们假设它有一个唯一的名称。我们把它\n",
    "#     # 保存在'Block'类的成员变量_children中。block的类型是OrderedDict。\n",
    "#     # 当MySequential实例调用initialize函数时，系统会自动初始化_children\n",
    "#     # 的所有成员\n",
    "#         self._children[block.name] = block\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "#         for block in self._children.values():\n",
    "#             X = block(X)\n",
    "#         return X\n",
    "   \n",
    "# net = MySequential()\n",
    "# net.add(nn.Dense(256, activation='relu'))\n",
    "# net.add(nn.Dense(10))\n",
    "# net.initialize()\n",
    "# net(X)\n",
    "\n",
    "\n",
    "class FixedHiddenMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # 使用get_constant函数创建的随机权重参数在训练期间不会更新（即为常量参数）\n",
    "        self.rand_weight = self.params.get_constant(\n",
    "            'rand_weight', np.random.uniform(size=(20, 20)))\n",
    "        self.dense = nn.Dense(20, activation='relu')\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.dense(X)\n",
    "        # 使用创建的常量参数以及relu和dot函数\n",
    "        X = npx.relu(np.dot(X, self.rand_weight.data()) + 1)\n",
    "        # 复用全连接层。这相当于两个全连接层共享参数\n",
    "        X = self.dense(X)\n",
    "        # 控制流\n",
    "        while np.abs(X).sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "  \n",
    "# net = FixedHiddenMLP()\n",
    "# net.initialize()\n",
    "# net(X)\n",
    "\n",
    "\n",
    "class NestMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add(nn.Dense(64, activation='relu'),\n",
    "                     nn.Dense(32, activation='relu'))\n",
    "        self.dense = nn.Dense(16, activation='relu')\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential()\n",
    "chimera.add(NestMLP(), nn.Dense(20), FixedHiddenMLP())\n",
    "chimera.initialize()\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f032fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b4b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
