{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0d40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv20 output shape:\t (1, 96, 54, 54)\n",
      "pool12 output shape:\t (1, 96, 26, 26)\n",
      "conv21 output shape:\t (1, 256, 26, 26)\n",
      "pool13 output shape:\t (1, 256, 12, 12)\n",
      "conv22 output shape:\t (1, 384, 12, 12)\n",
      "conv23 output shape:\t (1, 384, 12, 12)\n",
      "conv24 output shape:\t (1, 256, 12, 12)\n",
      "pool14 output shape:\t (1, 256, 5, 5)\n",
      "dense12 output shape:\t (1, 4096)\n",
      "dropout8 output shape:\t (1, 4096)\n",
      "dense13 output shape:\t (1, 4096)\n",
      "dropout9 output shape:\t (1, 4096)\n",
      "dense14 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "from mxnet import autograd, gluon, init, np, npx\n",
    "from mxnet.gluon import nn\n",
    "from matplotlib_inline import backend_inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    return npx.gpu(i) if npx.num_gpus() >= i + 1 else npx.cpu()\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "net = nn.Sequential()\n",
    "\n",
    "net.add(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2D(96, kernel_size=11, strides=4, activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=3, strides=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2D(256, kernel_size=5, padding=2, activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=3, strides=2),\n",
    "    # 使用三个连续的卷积层和一个较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 前两个卷积层后不使用汇聚层来减小输入的高和宽\n",
    "    nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "    nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
    "    nn.Conv2D(256, kernel_size=3, padding=1, activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=3, strides=2),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
    "    nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Dense(10))\n",
    "\n",
    "X = np.random.uniform(size=(1, 1, 224, 224))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape:\\t', X.shape)\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):  #@save\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if not device:  # 查询第一个参数所在的第一个设备\n",
    "        device = list(net.collect_params().values())[0].list_ctx()[0]\n",
    "    metric = Accumulator(2)  # 正确预测的数量，总预测的数量\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.as_in_ctx(device), y.as_in_ctx(device)\n",
    "        metric.add(accuracy(net(X), y), y.size)\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "class Timer:  #@save\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist() \n",
    "\n",
    "#@save\n",
    "class Accumulator: \n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "#@save\n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"设置matplotlib的轴\"\"\"\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()\n",
    "    \n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.astype(y.dtype) == y\n",
    "    return float(cmp.astype(y.dtype).sum())\n",
    "\n",
    "def use_svg_display():  #@save\n",
    "    \"\"\"使用svg格式在Jupyter中显示绘图\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        use_svg_display()\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda:  set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "#@save\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n",
    "    net.initialize(force_reinit=True, ctx=device, init=init.Xavier())\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = gluon.Trainer(net.collect_params(),\n",
    "                            'sgd', {'learning_rate': lr})\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(3)  # 训练损失之和，训练准确率之和，样本数\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            # 下面是与“train_epoch_ch3”的主要不同\n",
    "            X, y = X.as_in_ctx(device), y.as_in_ctx(device)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step(X.shape[0])\n",
    "            metric.add(l.sum(), accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')\n",
    "    \n",
    "def get_dataloader_workers():  #@save\n",
    "    \"\"\"在非Windows的平台上，使用4个进程来读取数据\"\"\"\n",
    "    return 0 if sys.platform.startswith('win') else 10\n",
    "    \n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    dataset = gluon.data.vision\n",
    "    trans = [dataset.transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, dataset.transforms.Resize(resize))\n",
    "    trans = dataset.transforms.Compose(trans)\n",
    "    mnist_train = dataset.FashionMNIST(train=True).transform_first(trans)\n",
    "    mnist_test = dataset.FashionMNIST(train=False).transform_first(trans)\n",
    "    return (gluon.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                                  num_workers=get_dataloader_workers()),\n",
    "            gluon.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                                  num_workers=get_dataloader_workers()))\n",
    "\n",
    "batch_size = 128\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save\n",
    "    \"\"\"绘制图像列表\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        ax.imshow(img.asnumpy())\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes\n",
    "\n",
    "lr, num_epochs = 0.01, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())\n",
    "\n",
    "def predict(net, test_iter, n=10):  #@save\n",
    "    \"\"\"预测标签（定义见第3章）\"\"\"\n",
    "    for X, y in test_iter:\n",
    "        break\n",
    "    trues = get_fashion_mnist_labels(y)\n",
    "    preds = get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    titles = [true +'\\n' + pred for true, pred in zip(trues, preds)]\n",
    "    show_images(\n",
    "        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])\n",
    "\n",
    "predict(net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e729d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
