{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c279117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n",
      "[ 0.  4.  8. 12.]\n",
      "epoch 1, loss 0.068386\n",
      "epoch 2, loss 0.068366\n",
      "epoch 3, loss 0.068347\n",
      "epoch 4, loss 0.068327\n",
      "epoch 5, loss 0.068307\n",
      "epoch 6, loss 0.068287\n",
      "epoch 7, loss 0.068268\n",
      "epoch 8, loss 0.068248\n",
      "epoch 9, loss 0.068228\n",
      "epoch 10, loss 0.068209\n",
      "epoch 11, loss 0.068189\n",
      "epoch 12, loss 0.068169\n",
      "epoch 13, loss 0.068150\n",
      "w的估计误差: [ 2.0226386 -3.3875885]\n",
      "b的估计误差: [4.190946]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib_inline import backend_inline\n",
    "from mxnet import autograd, np, npx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "x = np.arange(4.0)\n",
    "\n",
    "# 通过调用attach_grad来为一个张量的梯度分配内存\n",
    "x.attach_grad()\n",
    "# 在计算关于x的梯度后，将能够通过'grad'属性访问它，它的值被初始化为0\n",
    "x.grad\n",
    "# 把代码放到autograd.record内，以建立计算图\n",
    "with autograd.record():\n",
    "    y = 2 * np.dot(x, x)\n",
    " \n",
    "y.backward()\n",
    "print(y)\n",
    "print(x.grad)\n",
    "'''\n",
    "automatic differentiation\n",
    "computational graph\n",
    "backpropagate\n",
    "'''\n",
    "w = np.random.normal(0, 0.01, (2, 1))\n",
    "\n",
    "b = np.zeros(1)\n",
    "w.attach_grad()\n",
    "b.attach_grad()\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = np.random.normal(0, 1, (num_examples, len(w)))\n",
    "    y = np.dot(X, w) + b\n",
    "    y += np.random.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "def set_figsize(figsize=(3.5, 2.5)):  #@save\n",
    "    \"\"\"设置matplotlib的图表大小\"\"\"\n",
    "    use_svg_display()\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "    \n",
    "def use_svg_display():  #@save\n",
    "    \"\"\"使用svg格式在Jupyter中显示绘图\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "    \n",
    "    \n",
    "true_w = np.array([2, -3.4])\n",
    "true_b = 4.2\n",
    "\n",
    "features, labels = synthetic_data(true_w, true_b, 10)\n",
    "\n",
    "def linreg(X, w, b):  #@save\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return np.dot(X, w) + b\n",
    "\n",
    "\n",
    "def squared_loss(y_hat, y):  #@save\n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 276\n",
    "\n",
    "def sgd(params, lr, batch_size):  #@save\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad / batch_size\n",
    "\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = np.array(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "        \n",
    "lr = 0.03\n",
    "num_epochs = 13\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        with autograd.record():\n",
    "            l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 计算l关于[w,b]的梯度\n",
    "        l.backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "    \n",
    "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd9ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
